{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huyu/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 555:\n",
      "Image - Min Value: 10 Max Value: 254\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31c9f668d0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 555\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "features_0, labels_0 = helper.load_cfar10_batch(cifar10_dataset_folder_path, 1)\n",
    "print('Samples: {}'.format(len(features_0)))\n",
    "print('Label Counts: {}'.format(dict(zip(*np.unique(labels_0, return_counts=True)))))\n",
    "print('First 20 Labels: {}'.format(labels_0[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "air=[]\n",
    "mobile = []\n",
    "for index,value in enumerate(labels_0):\n",
    "    if value == 0:\n",
    "        air.append(features_0[index])\n",
    "    elif value == 1:\n",
    "        mobile.append(features_0[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f31c113b358>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f31c83acfd0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.axis('off')\n",
    "# plt.imshow(air[100])\n",
    "plt.imshow(air[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 10000\n",
      "Label Counts: {0: 984, 1: 1007, 2: 1010, 3: 995, 4: 1010, 5: 988, 6: 1008, 7: 1026, 8: 987, 9: 985}\n",
      "First 20 Labels: [1, 6, 6, 8, 8, 3, 4, 6, 0, 6, 0, 3, 6, 6, 5, 4, 8, 3, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_1, labels_1 = helper.load_cfar10_batch(cifar10_dataset_folder_path, 2)\n",
    "print('Samples: {}'.format(len(features_1)))\n",
    "print('Label Counts: {}'.format(dict(zip(*np.unique(labels_1, return_counts=True)))))\n",
    "print('First 20 Labels: {}'.format(labels_1[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,value in enumerate(labels_1):\n",
    "    if value == 0:\n",
    "        air.append(features_1[index])\n",
    "    elif value == 1:\n",
    "        mobile.append(features_1[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(features[0].shape)\n",
    "# plt.imshow(mobile[1716])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize x.shape =  (92, 32, 32, 3)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print(\"normalize x.shape = \",x.shape)\n",
    "    return x / 255.0\n",
    "\n",
    "\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize x.shape =  (1989, 32, 32, 3)\n",
      "normalize x.shape =  (1981, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# normalation\n",
    "air_normal = normalize(np.array(air))\n",
    "mobile_normal = normalize(np.array(mobile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_air = air_normal[:128]\n",
    "\n",
    "train_mobile = mobile_normal[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "valid_ari = air_normal[-1024:]\n",
    "valid_air_label = np.zeros(len(valid_ari))\n",
    "valid_mobile = mobile_normal[-1024:]\n",
    "valid_mobile_label = np.ones(len(valid_mobile))\n",
    "print(len(valid_ari))\n",
    "print(len(valid_mobile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(air_in,mobile_in):\n",
    "        feature_input = air_in + mobile_in\n",
    "        \n",
    "        print('len air_in = ',len(air_in))\n",
    "        air_label = np.zeros(len(air_in),dtype=np.int32)\n",
    "        mobile_label = np.ones(len(mobile_in),dtype=np.int32)\n",
    "        label_input = air_label + mobile_label\n",
    "        \n",
    "        air_object = np.random.permutation(air_in)\n",
    "        mobile_object = np.random.permutation(mobile_object)\n",
    "        feature_object = air_object + mobile_object\n",
    "        \n",
    "        \n",
    "        shuf_index = np.random.permutation(len(feature_input))\n",
    "        \n",
    "        return feature_input[shuf_index],feature_object[shuf_index],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_mobile[234])\n",
    "# print(train_mobile[234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_labels(air, mobile, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(air), batch_size):\n",
    "        end = min(start + batch_size, len(air))\n",
    "        \n",
    "        air_in = air[start:end]\n",
    "        mobile_in = mobile[start:end]\n",
    "        feature_input = np.concatenate((air_in , mobile_in)) \n",
    "        \n",
    "        lengh = len(air_in)\n",
    "#         print('len air_in = ',lengh)\n",
    "        air_label = np.zeros(lengh,dtype=np.int32)\n",
    "        mobile_label = np.ones(lengh,dtype=np.int32)\n",
    "        label_input =  np.concatenate((air_label , mobile_label))\n",
    "        \n",
    "        air_object = np.random.permutation(air_in)\n",
    "        mobile_object = np.random.permutation(mobile_in)\n",
    "        feature_object = np.concatenate((air_object , mobile_object))\n",
    "        \n",
    "        shuf_index = np.random.permutation(len(feature_input))\n",
    "        \n",
    "        yield feature_input[shuf_index],feature_object[shuf_index],label_input[shuf_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_features len =  (64, 32, 32, 3)\n",
      "batch_feature_object len =  [[[0.44705882 0.46666667 0.49019608]\n",
      "  [0.45882353 0.47843137 0.49411765]\n",
      "  [0.47058824 0.49411765 0.50588235]\n",
      "  ...\n",
      "  [0.64705882 0.65098039 0.62745098]\n",
      "  [0.49019608 0.49411765 0.4745098 ]\n",
      "  [0.40392157 0.40392157 0.43137255]]\n",
      "\n",
      " [[0.43529412 0.45490196 0.47843137]\n",
      "  [0.45490196 0.4745098  0.49803922]\n",
      "  [0.4745098  0.49411765 0.52156863]\n",
      "  ...\n",
      "  [0.63529412 0.63921569 0.61568627]\n",
      "  [0.49803922 0.50196078 0.48235294]\n",
      "  [0.40392157 0.40392157 0.42745098]]\n",
      "\n",
      " [[0.44705882 0.46666667 0.49019608]\n",
      "  [0.4745098  0.49019608 0.53333333]\n",
      "  [0.50196078 0.51764706 0.55686275]\n",
      "  ...\n",
      "  [0.65490196 0.65882353 0.63529412]\n",
      "  [0.51764706 0.52156863 0.49411765]\n",
      "  [0.41568627 0.42352941 0.4       ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.64705882 0.65098039 0.63137255]\n",
      "  [0.66666667 0.67058824 0.65490196]\n",
      "  [0.68627451 0.69019608 0.67058824]\n",
      "  ...\n",
      "  [0.7254902  0.70196078 0.65882353]\n",
      "  [0.81176471 0.78039216 0.76078431]\n",
      "  [0.78823529 0.75686275 0.7254902 ]]\n",
      "\n",
      " [[0.68627451 0.69019608 0.67058824]\n",
      "  [0.68627451 0.69019608 0.67058824]\n",
      "  [0.70588235 0.70980392 0.69019608]\n",
      "  ...\n",
      "  [0.73333333 0.71372549 0.63529412]\n",
      "  [0.78431373 0.76078431 0.70980392]\n",
      "  [0.75686275 0.72941176 0.69803922]]\n",
      "\n",
      " [[0.67843137 0.68235294 0.6627451 ]\n",
      "  [0.67058824 0.6745098  0.65490196]\n",
      "  [0.69411765 0.69803922 0.67843137]\n",
      "  ...\n",
      "  [0.80392157 0.78431373 0.71372549]\n",
      "  [0.82352941 0.8        0.75294118]\n",
      "  [0.79215686 0.76470588 0.73333333]]]\n",
      "batch_labels len =  (64,)\n",
      "[1 1 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1\n",
      " 1 0 0 1 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "for batch_features,batch_feature_object, batch_labels in batch_features_labels(train_air,train_mobile,32):\n",
    "    print('batch_features len = ',batch_features.shape)\n",
    "    print('batch_feature_object len = ',batch_feature_object[0])\n",
    "#     plt.imshow(batch_features[1])\n",
    "#     plt.imshow(batch_feature_object[0])\n",
    "    print('batch_labels len = ',batch_labels.shape)\n",
    "    print(batch_labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    print(image_shape)\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return tf.placeholder(dtype=tf.float32,shape=(None,*image_shape),name='x')\n",
    "\n",
    "def neural_net_image_object(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    print(image_shape)\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return tf.placeholder(dtype=tf.float32,shape=(None,*image_shape),name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(dtype=tf.int32,shape=(None),name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(dtype=tf.float32,name='keep_prob')\n",
    "\n",
    "def neural_net_regulation_scale():\n",
    "    return tf.placeholder(dtype=tf.float32,name='reguloss')\n",
    "\n",
    "def neural_new_is_training():\n",
    "    return tf.placeholder(dtype=tf.bool,name='is_training')\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "# \"\"\"\n",
    "# tf.reset_default_graph()\n",
    "# tests.test_nn_image_inputs(neural_net_image_input)\n",
    "# tests.test_nn_label_inputs(neural_net_label_input)\n",
    "# tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "\n",
    "x_o = neural_net_image_object((32,32,3))\n",
    "y = neural_net_label_input(1)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "reg_loss = neural_net_regulation_scale()\n",
    "is_training = neural_new_is_training();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.small_resnet import *\n",
    "import numpy as np\n",
    "from model import model_small_char as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool_1 =  [None, 16, 16, 32]\n",
      "MaxPool_2 =  [None, 16, 16, 64]\n",
      "MaxPool_3 =  [None, 8, 8, 64]\n",
      "MaxPool_4 =  [None, 4, 4, 256]\n",
      "net1 =  [None, 256]\n",
      "out =  [None, 2]\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "\n",
    "\n",
    "# Model\n",
    "network = model.NetWork(2)\n",
    "prelogits, decoded = network.buildNetWork(x,is_train= is_training,weight_decay = 5e-4,reuse= tf.AUTO_REUSE)\n",
    "\n",
    "# loss_decode = tf.nn.sigmoid_cross_entropy_with_logits(labels=x_o, logits=decoded)\n",
    "cost_decode = tf.reduce_mean(tf.pow(x_o - decoded, 2))\n",
    "\n",
    "loss_sig = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=prelogits)\n",
    "# loss_sig = tf.nn.sigmoid_cross_entropy_with_logits(labels=y,logits=prelogits)\n",
    "cost_sig = tf.reduce_mean(loss_sig)\n",
    "\n",
    "regule_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "\n",
    "cost = tf.add_n([cost_sig]+regule_loss,name='cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost += regulation_cost\n",
    "global_step = tf.Variable(0,trainable=False)\n",
    "initial_learning_rate = 0.001\n",
    "learning_rate = tf.train.exponential_decay(initial_learning_rate,global_step=global_step,decay_steps=500,decay_rate=0.95,staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost, global_step=global_step)\n",
    "keep_probability = 1.0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "predicted_gender = tf.nn.softmax(prelogits)\n",
    "correct_pred_gender= tf.equal( tf.argmax(predicted_gender,1,output_type=tf.int32),y)\n",
    "accuracy_gender = tf.reduce_mean(tf.cast(correct_pred_gender,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_old=[]\n",
    "arr_new =[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 1 1 0\n",
      " 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 0\n",
      " 1 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 1\n",
      " 1 0 1 0 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0\n",
      " 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6d4e1cd2fb60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(arr_old)\n",
    "plt.imshow(arr_new[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "epoch: 0\t batch_i: 2\tLoss 0.933\t loss_sigmod 0.840 \t loss_decode 0.000\n",
      "accuracy =  0.0\n",
      "epoch: 1\t batch_i: 2\tLoss 0.617\t loss_sigmod 0.523 \t loss_decode 0.000\n",
      "accuracy =  0.0\n",
      "epoch: 2\t batch_i: 2\tLoss 0.510\t loss_sigmod 0.417 \t loss_decode 0.000\n",
      "accuracy =  0.0\n",
      "epoch: 3\t batch_i: 2\tLoss 0.371\t loss_sigmod 0.278 \t loss_decode 0.000\n",
      "accuracy =  0.00390625\n",
      "epoch: 4\t batch_i: 2\tLoss 0.323\t loss_sigmod 0.230 \t loss_decode 0.000\n",
      "accuracy =  0.057617188\n",
      "epoch: 5\t batch_i: 2\tLoss 0.282\t loss_sigmod 0.188 \t loss_decode 0.000\n",
      "accuracy =  0.27246094\n",
      "epoch: 6\t batch_i: 2\tLoss 0.236\t loss_sigmod 0.143 \t loss_decode 0.000\n",
      "accuracy =  0.85058594\n",
      "epoch: 7\t batch_i: 2\tLoss 0.204\t loss_sigmod 0.111 \t loss_decode 0.000\n",
      "accuracy =  0.9902344\n",
      "epoch: 8\t batch_i: 2\tLoss 0.186\t loss_sigmod 0.093 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 9\t batch_i: 2\tLoss 0.168\t loss_sigmod 0.074 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 10\t batch_i: 2\tLoss 0.154\t loss_sigmod 0.060 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 11\t batch_i: 2\tLoss 0.137\t loss_sigmod 0.043 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 12\t batch_i: 2\tLoss 0.128\t loss_sigmod 0.035 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 13\t batch_i: 2\tLoss 0.120\t loss_sigmod 0.026 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 14\t batch_i: 2\tLoss 0.112\t loss_sigmod 0.019 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 15\t batch_i: 2\tLoss 0.111\t loss_sigmod 0.017 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 16\t batch_i: 2\tLoss 0.110\t loss_sigmod 0.016 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 17\t batch_i: 2\tLoss 0.107\t loss_sigmod 0.013 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 18\t batch_i: 2\tLoss 0.103\t loss_sigmod 0.009 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 19\t batch_i: 2\tLoss 0.101\t loss_sigmod 0.007 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 20\t batch_i: 2\tLoss 0.100\t loss_sigmod 0.006 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 21\t batch_i: 2\tLoss 0.099\t loss_sigmod 0.006 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 22\t batch_i: 2\tLoss 0.098\t loss_sigmod 0.005 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 23\t batch_i: 2\tLoss 0.098\t loss_sigmod 0.004 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 24\t batch_i: 2\tLoss 0.097\t loss_sigmod 0.004 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 25\t batch_i: 2\tLoss 0.096\t loss_sigmod 0.003 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 26\t batch_i: 2\tLoss 0.096\t loss_sigmod 0.003 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 27\t batch_i: 2\tLoss 0.095\t loss_sigmod 0.002 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 28\t batch_i: 2\tLoss 0.095\t loss_sigmod 0.002 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 29\t batch_i: 2\tLoss 0.095\t loss_sigmod 0.002 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 30\t batch_i: 2\tLoss 0.094\t loss_sigmod 0.002 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 31\t batch_i: 2\tLoss 0.094\t loss_sigmod 0.002 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 32\t batch_i: 2\tLoss 0.094\t loss_sigmod 0.002 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 33\t batch_i: 2\tLoss 0.093\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 34\t batch_i: 2\tLoss 0.093\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 35\t batch_i: 2\tLoss 0.093\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 36\t batch_i: 2\tLoss 0.093\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 37\t batch_i: 2\tLoss 0.092\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 38\t batch_i: 2\tLoss 0.092\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 39\t batch_i: 2\tLoss 0.092\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 40\t batch_i: 2\tLoss 0.092\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 41\t batch_i: 2\tLoss 0.092\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 42\t batch_i: 2\tLoss 0.091\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 43\t batch_i: 2\tLoss 0.091\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 44\t batch_i: 2\tLoss 0.091\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 45\t batch_i: 2\tLoss 0.091\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 46\t batch_i: 2\tLoss 0.090\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 47\t batch_i: 2\tLoss 0.090\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 48\t batch_i: 2\tLoss 0.090\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 49\t batch_i: 2\tLoss 0.090\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 50\t batch_i: 2\tLoss 0.090\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 51\t batch_i: 2\tLoss 0.089\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 52\t batch_i: 2\tLoss 0.089\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 53\t batch_i: 2\tLoss 0.089\t loss_sigmod 0.001 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 54\t batch_i: 2\tLoss 0.089\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 55\t batch_i: 2\tLoss 0.089\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 56\t batch_i: 2\tLoss 0.088\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 57\t batch_i: 2\tLoss 0.088\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 58\t batch_i: 2\tLoss 0.088\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 59\t batch_i: 2\tLoss 0.088\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 60\t batch_i: 2\tLoss 0.088\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 61\t batch_i: 2\tLoss 0.087\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 62\t batch_i: 2\tLoss 0.087\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 63\t batch_i: 2\tLoss 0.087\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 64\t batch_i: 2\tLoss 0.087\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 65\t batch_i: 2\tLoss 0.087\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 66\t batch_i: 2\tLoss 0.086\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 67\t batch_i: 2\tLoss 0.086\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 68\t batch_i: 2\tLoss 0.086\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 69\t batch_i: 2\tLoss 0.086\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 70\t batch_i: 2\tLoss 0.086\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 71\t batch_i: 2\tLoss 0.085\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 72\t batch_i: 2\tLoss 0.085\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 73\t batch_i: 2\tLoss 0.085\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 74\t batch_i: 2\tLoss 0.085\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 75\t batch_i: 2\tLoss 0.085\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 76\t batch_i: 2\tLoss 0.084\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 77\t batch_i: 2\tLoss 0.084\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 78\t batch_i: 2\tLoss 0.084\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n",
      "epoch: 79\t batch_i: 2\tLoss 0.084\t loss_sigmod 0.000 \t loss_decode 0.000\n",
      "accuracy =  1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "training\n",
    "\"\"\"\n",
    "epochs = 80\n",
    "cost_decode = tf.zeros(1)\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features,batch_feature_object, batch_labels in batch_features_labels(train_air,train_mobile,128):\n",
    "            arr_old = batch_labels\n",
    "            batch_i +=1\n",
    "            feed_dict={x:batch_features,y:batch_labels,x_o: batch_feature_object ,is_training:True}\n",
    "            _,loss,loss_s,step =  sess.run([optimizer,cost,cost_sig,global_step],feed_dict= feed_dict)\n",
    "            print('epoch: %d\\t batch_i: %d\\tLoss %2.3f\\t loss_sigmod %2.3f \\t loss_decode %2.3f'%(epoch,batch_i,loss,loss_s,0))\n",
    "        \n",
    "        feed_dict_v={x:valid_mobile,y:valid_mobile_label ,is_training:False}\n",
    "        accuary = sess.run(accuracy_gender,feed_dict= feed_dict_v)\n",
    "        print('accuracy = ',accuary)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
